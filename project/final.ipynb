{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Project\n",
    "\n",
    "Group 42 \n",
    "\n",
    "Quang Long Ho NGO, 310781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import json\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter # For Tensorboard\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation with DLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Feature extration with ResNet and a custom classification layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a pre-trained Resnet which extract the features using a CNN. Since we are using a version that was trained on IMAGENET-1K, the classification is not usable as it is for our task. The original classification layer was designed to classify between 1000 different classes however we only have 16 classes in our dataset. \n",
    "\n",
    "The motivation to use a pre-trained model is that since our dataset is too small, we can't trained it in order for it to pickup all the required details about a coin. It is easier to use a CNN that was trained to distinguish between objects in general and then fine-tune it to coin detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Pytorch as our machine learning framework. The first step is to create a usable dataset for Pytorch's DataLoaders. When loading the dataset, it is important to resize the images to the right dimensions (224x224) and normalize the images with the values it was used during pre-training (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]). We also add transforms such as random rotation, color jitter and random erasing to improve the performance on the validation set by fighting overfitting on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinDataset(Dataset):\n",
    "    \"\"\"DHMC dataset using 2 classes\"\"\"\n",
    "\n",
    "    def __init__(self, features_path : str, label_path, transform : bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            raw_data (list of dict): (M) List of M slides raw data as dictionaries. \n",
    "            train (bool): True if data are the training set. False otherwise\n",
    "            \n",
    "        Args:\n",
    "            features_path (str): The path to the features file\n",
    "            train (bool): Whether it is the training dataset or not\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.raw_data = []\n",
    "        data_json = None\n",
    "        with open(label_path, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "        for x in data_json:\n",
    "            filename = x[\"filename\"]\n",
    "            img_path = f\"{features_path}/{filename}\"\n",
    "            img = Image.open(img_path)\n",
    "            self.raw_data.append({\"image_features\": img, \"label\": int(x[\"value\"])})\n",
    "        \n",
    "        if transform:\n",
    "            self.transform = v2.Compose([\n",
    "                v2.Resize(224),\n",
    "                v2.RandomRotation(degrees=(0, 300)),\n",
    "                v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.4, hue=0.3),\n",
    "                v2.ToTensor(),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                v2.RandomErasing(p=0.5)\n",
    "                ])\n",
    "        else:\n",
    "            self.transform = v2.Compose([\n",
    "                v2.Resize(224),\n",
    "                v2.CenterCrop(224),\n",
    "                v2.ToTensor(),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the dataset\n",
    "\n",
    "        Returns:\n",
    "            int: The length M of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        n_data = len(self.raw_data)\n",
    "        return n_data\n",
    "    \n",
    "    def __getitem__(self, index : int):\n",
    "        \"\"\"Returns the entry at index from the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): the requested entry index of the dataset\n",
    "\n",
    "        Returns:\n",
    "            features (torch.Tensor): (N, d) Feature tensor of the selected slide with N patches and d feature dimensions\n",
    "            label (int): Ground truth label {0, ..., n_classes}\n",
    "            wsi_id (str): Name of the WSI as \"DHMC_xxx\" where xxx is a unique id of the slide (train == False only)\n",
    "            coordinates (torch.Tensor): (N, 2) xy coordinates of the N patches of the selected slide (train == False only)\n",
    "        \"\"\"\n",
    "\n",
    "        features = None\n",
    "        label = None\n",
    "\n",
    "        features = self.raw_data[index][\"image_features\"]\n",
    "        label = torch.tensor(self.raw_data[index][\"label\"])\n",
    "    \n",
    "        features = self.transform(features)\n",
    "        return features, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only apply the transforms on the testing dataset. The train loader will use a batch_size of 32 which helps stabilize the training. We also shuffle so that the learning is not biased by the order of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the img from output folder and make a dataset\n",
    "train_coinDataset = CoinDataset('./output/', \"train_data_split.json\", transform=True)\n",
    "val_coinDataset = CoinDataset('./output/', \"val_data_split.json\", transform=False)\n",
    "# trans = tranosforms.Compose([transforms.Resize(256),transforms.ToTensor()])\n",
    "\n",
    "train_loader = DataLoader(train_coinDataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_coinDataset, batch_size=len(val_coinDataset), shuffle=False)\n",
    "# dataset = datasets.ImaVgeFolder('./output-1/', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the resnet152 model with pre-trained weights from IMAGENET1K. Dropout and batch normalization was added to the custom classfication layer to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "model = resnet152(weights=ResNet152_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 16)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained with an Adam optimizer with a learning rate of $1e-4$ and we are using a scheduler to reduce the learning rate if the validation loss is not going down during 10 consecutive epochs. Cross entropy loss is used which is standard for multiple class classification tasks. The model is trained for 25 epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs=10):\n",
    "    \n",
    "    model.to(device)\n",
    "    steps = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = accuracy_score(target, output.argmax(dim=1, keepdim=True))\n",
    "            writer.add_scalar(\"Acc/train\", acc, steps)\n",
    "            writer.add_scalar(\"Loss/train\", loss, steps)\n",
    "            steps+=1\n",
    "            if i % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Acc: {:.3f}'.format(\n",
    "                    epoch, i * len(data), len(train_loader.dataset),\n",
    "                    100. * i / len(train_loader), loss.item(), acc*100))\n",
    "                \n",
    "\n",
    "        running_vloss = []\n",
    "        val_f1micro = []\n",
    "        val_f1macro = []\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss.append(vloss)\n",
    "                pred = voutputs.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(vlabels.view_as(pred)).sum().item()\n",
    "                val_f1micro.append(f1_score(pred, vlabels, average='micro'))\n",
    "                val_f1macro.append(f1_score(pred, vlabels, average='macro'))\n",
    "\n",
    "        avg_vloss = np.mean(running_vloss)\n",
    "        avg_vf1micro = np.mean(val_f1micro)\n",
    "        avg_vf1macro = np.mean(val_f1macro)\n",
    "\n",
    "        val_accuracy = 100. * correct / len(val_loader.dataset)\n",
    "        print('Val Epoch: {}\\tLoss: {:.6f}, Acc: {:.3f}, F1 micro: {:.3f}'.format(\n",
    "            epoch, avg_vloss, val_accuracy, avg_vf1micro\n",
    "        ))\n",
    "\n",
    "        writer.add_scalar(\"Loss/val\", avg_vloss, (epoch + 1))\n",
    "        writer.add_scalar(\"Acc/val\", val_accuracy, (epoch + 1))\n",
    "        writer.add_scalar(\"F1_micro/val\", avg_vf1micro, epoch + 1)\n",
    "        writer.add_scalar(\"F1_macro/val\", avg_vf1macro, epoch + 1)\n",
    "        scheduler.step(avg_vloss)\n",
    "                \n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "# Log in Tensorboard\n",
    "writer = SummaryWriter('runs/efficientnet_v2_s_baseline')\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, scheduler, nn.CrossEntropyLoss(), epochs=25)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
