{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x169252690>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# import numpy as np\n",
    "# Import main packages\n",
    "import os\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import json\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter # For Tensorboard\n",
    "from collections.abc import Mapping\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinDataset(Dataset):\n",
    "    \"\"\"DHMC dataset using 2 classes\"\"\"\n",
    "\n",
    "    def __init__(self, features_path : str, label_path,train : bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            raw_data (list of dict): (M) List of M slides raw data as dictionaries. \n",
    "            train (bool): True if data are the training set. False otherwise\n",
    "            \n",
    "        Args:\n",
    "            features_path (str): The path to the features file\n",
    "            train (bool): Whether it is the training dataset or not\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # Load raw data from path\n",
    "        \n",
    "        # self.raw_data = torch.load(features_path)\n",
    "        # load labels from json file\n",
    "        self.raw_data = []\n",
    "        data_json = None\n",
    "        with open(label_path, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "        for x in data_json:\n",
    "            filename = x[\"filename\"]\n",
    "            img_path = f\"{features_path}/{filename}\"\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            mean=[0.485, 0.456, 0.406]\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "            img = transform(img)\n",
    "            # print(img_tr)\n",
    "            # img = np.array(img_tr)\n",
    "            # print(img)\n",
    "            # img = img.flatten()\n",
    "            self.raw_data.append({\"image_features\": img, \"label\": int(x[\"value\"])})\n",
    "\n",
    "            #open image\n",
    "        # Set if training or not\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the dataset\n",
    "\n",
    "        Returns:\n",
    "            int: The length M of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        n_data = 0\n",
    "        \n",
    "        # ------------------\n",
    "        # Your code here ... \n",
    "        # ------------------\n",
    "        n_data = len(self.raw_data)\n",
    "        return n_data\n",
    "    \n",
    "    def __getitem__(self, index : int):\n",
    "        \"\"\"Returns the entry at index from the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): the requested entry index of the dataset\n",
    "\n",
    "        Returns:\n",
    "            features (torch.Tensor): (N, d) Feature tensor of the selected slide with N patches and d feature dimensions\n",
    "            label (int): Ground truth label {0, ..., n_classes}\n",
    "            wsi_id (str): Name of the WSI as \"DHMC_xxx\" where xxx is a unique id of the slide (train == False only)\n",
    "            coordinates (torch.Tensor): (N, 2) xy coordinates of the N patches of the selected slide (train == False only)\n",
    "        \"\"\"\n",
    "\n",
    "        features = None\n",
    "        label = None\n",
    "        wsi_id = None\n",
    "        coordinates = None\n",
    "        \n",
    "        # ------------------\n",
    "        # Your code here ... \n",
    "        # ------------------\n",
    "        features = torch.tensor(self.raw_data[index][\"image_features\"]).float()\n",
    "        label = torch.tensor(self.raw_data[index][\"label\"])\n",
    "        # coordinates = self.raw_data[index][\"patch_coordinates\"]\n",
    "        # wsi_id = self.raw_data[index][\"wsi_id\"]\n",
    "        # if self.train:\n",
    "        return features, label\n",
    "        # else:\n",
    "        #     return features, label, wsi_id, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_split() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.9\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(coinDataset))\n\u001b[1;32m      7\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(coinDataset) \u001b[38;5;241m-\u001b[39m train_size\n\u001b[0;32m----> 8\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoinDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: random_split() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "# Load all the img from output folder and make a dataset\n",
    "coinDataset = CoinDataset('./output/', \"train_data.json\", train=True)\n",
    "# trans = tranosforms.Compose([transforms.Resize(256),transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_size = int(0.9* len(coinDataset))\n",
    "val_size = len(coinDataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(coinDataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "# dataset = datasets.ImaVgeFolder('./output-1/', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 16)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/v89fg7g56hb9fx7z3ymhhp4m0000gn/T/ipykernel_8762/1542035511.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(self.raw_data[index][\"image_features\"]).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/343 (0%)]\tLoss: 2.863131\n",
      "Train Epoch: 0 [230/343 (91%)]\tLoss: 2.632176\n",
      "Val Epoch: 0\tLoss: 2.837209\n",
      "Train Epoch: 1 [0/343 (0%)]\tLoss: 2.276372\n",
      "Train Epoch: 1 [230/343 (91%)]\tLoss: 2.213240\n",
      "Val Epoch: 1\tLoss: 2.793255\n",
      "Train Epoch: 2 [0/343 (0%)]\tLoss: 2.003725\n",
      "Train Epoch: 2 [230/343 (91%)]\tLoss: 1.560597\n",
      "Val Epoch: 2\tLoss: 2.827165\n",
      "Train Epoch: 3 [0/343 (0%)]\tLoss: 1.367268\n",
      "Train Epoch: 3 [230/343 (91%)]\tLoss: 1.378609\n",
      "Val Epoch: 3\tLoss: 2.816723\n",
      "Train Epoch: 4 [0/343 (0%)]\tLoss: 1.265505\n",
      "Train Epoch: 4 [230/343 (91%)]\tLoss: 0.873668\n",
      "Val Epoch: 4\tLoss: 2.830498\n",
      "Train Epoch: 5 [0/343 (0%)]\tLoss: 0.802562\n",
      "Train Epoch: 5 [230/343 (91%)]\tLoss: 0.813830\n",
      "Val Epoch: 5\tLoss: 2.830173\n",
      "Train Epoch: 6 [0/343 (0%)]\tLoss: 0.612891\n",
      "Train Epoch: 6 [230/343 (91%)]\tLoss: 0.438868\n",
      "Val Epoch: 6\tLoss: 2.891581\n",
      "Train Epoch: 7 [0/343 (0%)]\tLoss: 0.378432\n",
      "Train Epoch: 7 [230/343 (91%)]\tLoss: 0.531261\n",
      "Val Epoch: 7\tLoss: 2.817993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs=10):\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar(\"Loss/train\", loss, steps)\n",
    "            steps+=1\n",
    "            if i % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, i * len(data), len(train_loader.dataset),\n",
    "                    100. * i / len(train_loader), loss.item()))\n",
    "                \n",
    "\n",
    "        running_vloss = []\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss.append(vloss)\n",
    "\n",
    "        avg_vloss = np.mean(running_vloss)\n",
    "        print('Val Epoch: {}\\tLoss: {:.6f}'.format(\n",
    "            epoch, avg_vloss\n",
    "        ))\n",
    "        writer.add_scalar(\"Loss/val\", avg_vloss, (epoch + 1))\n",
    "        scheduler.step()\n",
    "                \n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Log in Tensorboard\n",
    "writer = SummaryWriter('runs/simple_restnet18_1e-4')\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, scheduler, nn.CrossEntropyLoss(), epochs=8)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
