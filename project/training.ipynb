{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# import numpy as np\n",
    "# Import main packages\n",
    "import os\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import json\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinDataset(Dataset):\n",
    "    \"\"\"DHMC dataset using 2 classes\"\"\"\n",
    "\n",
    "    def __init__(self, features_path : str, label_path,train : bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            raw_data (list of dict): (M) List of M slides raw data as dictionaries. \n",
    "            train (bool): True if data are the training set. False otherwise\n",
    "            \n",
    "        Args:\n",
    "            features_path (str): The path to the features file\n",
    "            train (bool): Whether it is the training dataset or not\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        # Load raw data from path\n",
    "        \n",
    "        # self.raw_data = torch.load(features_path)\n",
    "        # load labels from json file\n",
    "        self.raw_data = []\n",
    "        data_json = None\n",
    "        with open(label_path, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "        for x in data_json:\n",
    "            filename = x[\"filename\"]\n",
    "            img_path = f\"{features_path}/{filename}\"\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            mean=[0.485, 0.456, 0.406]\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "            img = transform(img)\n",
    "            # print(img_tr)\n",
    "            # img = np.array(img_tr)\n",
    "            # print(img)\n",
    "            # img = img.flatten()\n",
    "            self.raw_data.append({\"image_features\": img, \"label\": int(x[\"value\"])})\n",
    "\n",
    "            #open image\n",
    "        # Set if training or not\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the dataset\n",
    "\n",
    "        Returns:\n",
    "            int: The length M of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        n_data = 0\n",
    "        \n",
    "        # ------------------\n",
    "        # Your code here ... \n",
    "        # ------------------\n",
    "        n_data = len(self.raw_data)\n",
    "        return n_data\n",
    "    \n",
    "    def __getitem__(self, index : int):\n",
    "        \"\"\"Returns the entry at index from the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): the requested entry index of the dataset\n",
    "\n",
    "        Returns:\n",
    "            features (torch.Tensor): (N, d) Feature tensor of the selected slide with N patches and d feature dimensions\n",
    "            label (int): Ground truth label {0, ..., n_classes}\n",
    "            wsi_id (str): Name of the WSI as \"DHMC_xxx\" where xxx is a unique id of the slide (train == False only)\n",
    "            coordinates (torch.Tensor): (N, 2) xy coordinates of the N patches of the selected slide (train == False only)\n",
    "        \"\"\"\n",
    "\n",
    "        features = None\n",
    "        label = None\n",
    "        wsi_id = None\n",
    "        coordinates = None\n",
    "        \n",
    "        # ------------------\n",
    "        # Your code here ... \n",
    "        # ------------------\n",
    "        features = torch.tensor(self.raw_data[index][\"image_features\"]).float()\n",
    "        label = torch.tensor(self.raw_data[index][\"label\"])\n",
    "        # coordinates = self.raw_data[index][\"patch_coordinates\"]\n",
    "        # wsi_id = self.raw_data[index][\"wsi_id\"]\n",
    "        # if self.train:\n",
    "        return features, label\n",
    "        # else:\n",
    "        #     return features, label, wsi_id, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the img from output folder and make a dataset\n",
    "coinDataset = CoinDataset('./output/', \"train_data.json\", train=True)\n",
    "# trans = tranosforms.Compose([transforms.Resize(256),transforms.ToTensor()])\n",
    "train_loader = DataLoader(coinDataset, batch_size=1, shuffle=True)\n",
    "# dataset = datasets.ImaVgeFolder('./output-1/', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 16)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/v89fg7g56hb9fx7z3ymhhp4m0000gn/T/ipykernel_96376/1542035511.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(self.raw_data[index][\"image_features\"]).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/382 (0%)]\tLoss: 2.387052\n",
      "Train Epoch: 0 [10/382 (3%)]\tLoss: 2.985427\n",
      "Train Epoch: 0 [20/382 (5%)]\tLoss: 2.560836\n",
      "Train Epoch: 0 [30/382 (8%)]\tLoss: 3.068016\n",
      "Train Epoch: 0 [40/382 (10%)]\tLoss: 2.210358\n",
      "Train Epoch: 0 [50/382 (13%)]\tLoss: 3.737090\n",
      "Train Epoch: 0 [60/382 (16%)]\tLoss: 2.537976\n",
      "Train Epoch: 0 [70/382 (18%)]\tLoss: 2.005456\n",
      "Train Epoch: 0 [80/382 (21%)]\tLoss: 1.725199\n",
      "Train Epoch: 0 [90/382 (24%)]\tLoss: 3.004172\n",
      "Train Epoch: 0 [100/382 (26%)]\tLoss: 2.685013\n",
      "Train Epoch: 0 [110/382 (29%)]\tLoss: 2.653685\n",
      "Train Epoch: 0 [120/382 (31%)]\tLoss: 2.124725\n",
      "Train Epoch: 0 [130/382 (34%)]\tLoss: 2.514086\n",
      "Train Epoch: 0 [140/382 (37%)]\tLoss: 2.653254\n",
      "Train Epoch: 0 [150/382 (39%)]\tLoss: 3.856172\n",
      "Train Epoch: 0 [160/382 (42%)]\tLoss: 2.245568\n",
      "Train Epoch: 0 [170/382 (45%)]\tLoss: 3.120234\n",
      "Train Epoch: 0 [180/382 (47%)]\tLoss: 2.832537\n",
      "Train Epoch: 0 [190/382 (50%)]\tLoss: 3.513852\n",
      "Train Epoch: 0 [200/382 (52%)]\tLoss: 3.723752\n",
      "Train Epoch: 0 [210/382 (55%)]\tLoss: 3.015148\n",
      "Train Epoch: 0 [220/382 (58%)]\tLoss: 3.384464\n",
      "Train Epoch: 0 [230/382 (60%)]\tLoss: 2.422451\n",
      "Train Epoch: 0 [240/382 (63%)]\tLoss: 3.005087\n",
      "Train Epoch: 0 [250/382 (65%)]\tLoss: 3.098509\n",
      "Train Epoch: 0 [260/382 (68%)]\tLoss: 2.905393\n",
      "Train Epoch: 0 [270/382 (71%)]\tLoss: 2.635765\n",
      "Train Epoch: 0 [280/382 (73%)]\tLoss: 2.585507\n",
      "Train Epoch: 0 [290/382 (76%)]\tLoss: 2.845469\n",
      "Train Epoch: 0 [300/382 (79%)]\tLoss: 2.772669\n",
      "Train Epoch: 0 [310/382 (81%)]\tLoss: 2.099468\n",
      "Train Epoch: 0 [320/382 (84%)]\tLoss: 2.925006\n",
      "Train Epoch: 0 [330/382 (86%)]\tLoss: 2.802282\n",
      "Train Epoch: 0 [340/382 (89%)]\tLoss: 2.731993\n",
      "Train Epoch: 0 [350/382 (92%)]\tLoss: 2.515404\n",
      "Train Epoch: 0 [360/382 (94%)]\tLoss: 2.891406\n",
      "Train Epoch: 0 [370/382 (97%)]\tLoss: 3.190554\n",
      "Train Epoch: 0 [380/382 (99%)]\tLoss: 2.620398\n",
      "Train Epoch: 1 [0/382 (0%)]\tLoss: 2.819753\n",
      "Train Epoch: 1 [10/382 (3%)]\tLoss: 2.636614\n",
      "Train Epoch: 1 [20/382 (5%)]\tLoss: 2.385691\n",
      "Train Epoch: 1 [30/382 (8%)]\tLoss: 2.294802\n",
      "Train Epoch: 1 [40/382 (10%)]\tLoss: 3.462686\n",
      "Train Epoch: 1 [50/382 (13%)]\tLoss: 2.804523\n",
      "Train Epoch: 1 [60/382 (16%)]\tLoss: 2.657641\n",
      "Train Epoch: 1 [70/382 (18%)]\tLoss: 2.792664\n",
      "Train Epoch: 1 [80/382 (21%)]\tLoss: 2.489329\n",
      "Train Epoch: 1 [90/382 (24%)]\tLoss: 2.690267\n",
      "Train Epoch: 1 [100/382 (26%)]\tLoss: 2.401104\n",
      "Train Epoch: 1 [110/382 (29%)]\tLoss: 2.666083\n",
      "Train Epoch: 1 [120/382 (31%)]\tLoss: 2.260259\n",
      "Train Epoch: 1 [130/382 (34%)]\tLoss: 2.478179\n",
      "Train Epoch: 1 [140/382 (37%)]\tLoss: 2.780054\n",
      "Train Epoch: 1 [150/382 (39%)]\tLoss: 2.042671\n",
      "Train Epoch: 1 [160/382 (42%)]\tLoss: 3.042273\n",
      "Train Epoch: 1 [170/382 (45%)]\tLoss: 3.048642\n",
      "Train Epoch: 1 [180/382 (47%)]\tLoss: 2.624198\n",
      "Train Epoch: 1 [190/382 (50%)]\tLoss: 2.739047\n",
      "Train Epoch: 1 [200/382 (52%)]\tLoss: 2.470679\n",
      "Train Epoch: 1 [210/382 (55%)]\tLoss: 2.673898\n",
      "Train Epoch: 1 [220/382 (58%)]\tLoss: 2.532670\n",
      "Train Epoch: 1 [230/382 (60%)]\tLoss: 2.527322\n",
      "Train Epoch: 1 [240/382 (63%)]\tLoss: 2.429197\n",
      "Train Epoch: 1 [250/382 (65%)]\tLoss: 3.547106\n",
      "Train Epoch: 1 [260/382 (68%)]\tLoss: 2.403417\n",
      "Train Epoch: 1 [270/382 (71%)]\tLoss: 1.857462\n",
      "Train Epoch: 1 [280/382 (73%)]\tLoss: 2.657915\n",
      "Train Epoch: 1 [290/382 (76%)]\tLoss: 2.618121\n",
      "Train Epoch: 1 [300/382 (79%)]\tLoss: 3.318857\n",
      "Train Epoch: 1 [310/382 (81%)]\tLoss: 2.850366\n",
      "Train Epoch: 1 [320/382 (84%)]\tLoss: 2.178877\n",
      "Train Epoch: 1 [330/382 (86%)]\tLoss: 2.735922\n",
      "Train Epoch: 1 [340/382 (89%)]\tLoss: 2.452829\n",
      "Train Epoch: 1 [350/382 (92%)]\tLoss: 2.807532\n",
      "Train Epoch: 1 [360/382 (94%)]\tLoss: 2.821050\n",
      "Train Epoch: 1 [370/382 (97%)]\tLoss: 2.126731\n",
      "Train Epoch: 1 [380/382 (99%)]\tLoss: 2.400382\n",
      "Train Epoch: 2 [0/382 (0%)]\tLoss: 2.729384\n",
      "Train Epoch: 2 [10/382 (3%)]\tLoss: 2.994007\n",
      "Train Epoch: 2 [20/382 (5%)]\tLoss: 3.296256\n",
      "Train Epoch: 2 [30/382 (8%)]\tLoss: 2.580771\n",
      "Train Epoch: 2 [40/382 (10%)]\tLoss: 2.741532\n",
      "Train Epoch: 2 [50/382 (13%)]\tLoss: 2.977139\n",
      "Train Epoch: 2 [60/382 (16%)]\tLoss: 2.726776\n",
      "Train Epoch: 2 [70/382 (18%)]\tLoss: 2.414082\n",
      "Train Epoch: 2 [80/382 (21%)]\tLoss: 2.556765\n",
      "Train Epoch: 2 [90/382 (24%)]\tLoss: 3.395394\n",
      "Train Epoch: 2 [100/382 (26%)]\tLoss: 2.392422\n",
      "Train Epoch: 2 [110/382 (29%)]\tLoss: 3.275912\n",
      "Train Epoch: 2 [120/382 (31%)]\tLoss: 2.600174\n",
      "Train Epoch: 2 [130/382 (34%)]\tLoss: 3.050198\n",
      "Train Epoch: 2 [140/382 (37%)]\tLoss: 2.547338\n",
      "Train Epoch: 2 [150/382 (39%)]\tLoss: 2.829584\n",
      "Train Epoch: 2 [160/382 (42%)]\tLoss: 2.537879\n",
      "Train Epoch: 2 [170/382 (45%)]\tLoss: 2.482658\n",
      "Train Epoch: 2 [180/382 (47%)]\tLoss: 2.270864\n",
      "Train Epoch: 2 [190/382 (50%)]\tLoss: 2.512096\n",
      "Train Epoch: 2 [200/382 (52%)]\tLoss: 5.103025\n",
      "Train Epoch: 2 [210/382 (55%)]\tLoss: 2.374495\n",
      "Train Epoch: 2 [220/382 (58%)]\tLoss: 3.329902\n",
      "Train Epoch: 2 [230/382 (60%)]\tLoss: 2.631849\n",
      "Train Epoch: 2 [240/382 (63%)]\tLoss: 2.698788\n",
      "Train Epoch: 2 [250/382 (65%)]\tLoss: 2.665626\n",
      "Train Epoch: 2 [260/382 (68%)]\tLoss: 3.346157\n",
      "Train Epoch: 2 [270/382 (71%)]\tLoss: 2.702135\n",
      "Train Epoch: 2 [280/382 (73%)]\tLoss: 2.784848\n",
      "Train Epoch: 2 [290/382 (76%)]\tLoss: 2.594398\n",
      "Train Epoch: 2 [300/382 (79%)]\tLoss: 3.130334\n",
      "Train Epoch: 2 [310/382 (81%)]\tLoss: 2.576111\n",
      "Train Epoch: 2 [320/382 (84%)]\tLoss: 2.624716\n",
      "Train Epoch: 2 [330/382 (86%)]\tLoss: 3.223074\n",
      "Train Epoch: 2 [340/382 (89%)]\tLoss: 2.790860\n",
      "Train Epoch: 2 [350/382 (92%)]\tLoss: 2.633859\n",
      "Train Epoch: 2 [360/382 (94%)]\tLoss: 3.041951\n",
      "Train Epoch: 2 [370/382 (97%)]\tLoss: 2.767013\n",
      "Train Epoch: 2 [380/382 (99%)]\tLoss: 2.724253\n",
      "Train Epoch: 3 [0/382 (0%)]\tLoss: 2.775753\n",
      "Train Epoch: 3 [10/382 (3%)]\tLoss: 3.080602\n",
      "Train Epoch: 3 [20/382 (5%)]\tLoss: 3.015911\n",
      "Train Epoch: 3 [30/382 (8%)]\tLoss: 2.854963\n",
      "Train Epoch: 3 [40/382 (10%)]\tLoss: 2.735931\n",
      "Train Epoch: 3 [50/382 (13%)]\tLoss: 2.280381\n",
      "Train Epoch: 3 [60/382 (16%)]\tLoss: 2.668064\n",
      "Train Epoch: 3 [70/382 (18%)]\tLoss: 3.156446\n",
      "Train Epoch: 3 [80/382 (21%)]\tLoss: 3.110049\n",
      "Train Epoch: 3 [90/382 (24%)]\tLoss: 2.405698\n",
      "Train Epoch: 3 [100/382 (26%)]\tLoss: 2.348130\n",
      "Train Epoch: 3 [110/382 (29%)]\tLoss: 1.975328\n",
      "Train Epoch: 3 [120/382 (31%)]\tLoss: 2.652745\n",
      "Train Epoch: 3 [130/382 (34%)]\tLoss: 2.734902\n",
      "Train Epoch: 3 [140/382 (37%)]\tLoss: 3.020066\n",
      "Train Epoch: 3 [150/382 (39%)]\tLoss: 2.137654\n",
      "Train Epoch: 3 [160/382 (42%)]\tLoss: 2.407799\n",
      "Train Epoch: 3 [170/382 (45%)]\tLoss: 2.676535\n",
      "Train Epoch: 3 [180/382 (47%)]\tLoss: 3.082642\n",
      "Train Epoch: 3 [190/382 (50%)]\tLoss: 2.654322\n",
      "Train Epoch: 3 [200/382 (52%)]\tLoss: 2.643017\n",
      "Train Epoch: 3 [210/382 (55%)]\tLoss: 2.187065\n",
      "Train Epoch: 3 [220/382 (58%)]\tLoss: 3.057636\n",
      "Train Epoch: 3 [230/382 (60%)]\tLoss: 2.735989\n",
      "Train Epoch: 3 [240/382 (63%)]\tLoss: 3.246096\n",
      "Train Epoch: 3 [250/382 (65%)]\tLoss: 2.618504\n",
      "Train Epoch: 3 [260/382 (68%)]\tLoss: 2.735449\n",
      "Train Epoch: 3 [270/382 (71%)]\tLoss: 2.809893\n",
      "Train Epoch: 3 [280/382 (73%)]\tLoss: 3.006796\n",
      "Train Epoch: 3 [290/382 (76%)]\tLoss: 3.026004\n",
      "Train Epoch: 3 [300/382 (79%)]\tLoss: 2.932247\n",
      "Train Epoch: 3 [310/382 (81%)]\tLoss: 2.588056\n",
      "Train Epoch: 3 [320/382 (84%)]\tLoss: 2.226014\n",
      "Train Epoch: 3 [330/382 (86%)]\tLoss: 2.681611\n",
      "Train Epoch: 3 [340/382 (89%)]\tLoss: 2.642128\n",
      "Train Epoch: 3 [350/382 (92%)]\tLoss: 2.068695\n",
      "Train Epoch: 3 [360/382 (94%)]\tLoss: 1.979073\n",
      "Train Epoch: 3 [370/382 (97%)]\tLoss: 3.413740\n",
      "Train Epoch: 3 [380/382 (99%)]\tLoss: 2.935688\n",
      "Train Epoch: 4 [0/382 (0%)]\tLoss: 1.944843\n",
      "Train Epoch: 4 [10/382 (3%)]\tLoss: 2.643303\n",
      "Train Epoch: 4 [20/382 (5%)]\tLoss: 2.893390\n",
      "Train Epoch: 4 [30/382 (8%)]\tLoss: 3.174971\n",
      "Train Epoch: 4 [40/382 (10%)]\tLoss: 2.626738\n",
      "Train Epoch: 4 [50/382 (13%)]\tLoss: 2.643003\n",
      "Train Epoch: 4 [60/382 (16%)]\tLoss: 2.617582\n",
      "Train Epoch: 4 [70/382 (18%)]\tLoss: 2.616889\n",
      "Train Epoch: 4 [80/382 (21%)]\tLoss: 3.002326\n",
      "Train Epoch: 4 [90/382 (24%)]\tLoss: 3.026684\n",
      "Train Epoch: 4 [100/382 (26%)]\tLoss: 2.569432\n",
      "Train Epoch: 4 [110/382 (29%)]\tLoss: 2.776883\n",
      "Train Epoch: 4 [120/382 (31%)]\tLoss: 2.665397\n",
      "Train Epoch: 4 [130/382 (34%)]\tLoss: 2.768113\n",
      "Train Epoch: 4 [140/382 (37%)]\tLoss: 2.541826\n",
      "Train Epoch: 4 [150/382 (39%)]\tLoss: 2.655715\n",
      "Train Epoch: 4 [160/382 (42%)]\tLoss: 2.873082\n",
      "Train Epoch: 4 [170/382 (45%)]\tLoss: 2.624552\n",
      "Train Epoch: 4 [180/382 (47%)]\tLoss: 2.592598\n",
      "Train Epoch: 4 [190/382 (50%)]\tLoss: 2.291475\n",
      "Train Epoch: 4 [200/382 (52%)]\tLoss: 3.266917\n",
      "Train Epoch: 4 [210/382 (55%)]\tLoss: 3.082394\n",
      "Train Epoch: 4 [220/382 (58%)]\tLoss: 2.911129\n",
      "Train Epoch: 4 [230/382 (60%)]\tLoss: 3.166375\n",
      "Train Epoch: 4 [240/382 (63%)]\tLoss: 2.589632\n",
      "Train Epoch: 4 [250/382 (65%)]\tLoss: 2.734966\n",
      "Train Epoch: 4 [260/382 (68%)]\tLoss: 3.356727\n",
      "Train Epoch: 4 [270/382 (71%)]\tLoss: 2.999217\n",
      "Train Epoch: 4 [280/382 (73%)]\tLoss: 2.697030\n",
      "Train Epoch: 4 [290/382 (76%)]\tLoss: 1.988000\n",
      "Train Epoch: 4 [300/382 (79%)]\tLoss: 2.639427\n",
      "Train Epoch: 4 [310/382 (81%)]\tLoss: 1.793704\n",
      "Train Epoch: 4 [320/382 (84%)]\tLoss: 1.796159\n",
      "Train Epoch: 4 [330/382 (86%)]\tLoss: 2.775594\n",
      "Train Epoch: 4 [340/382 (89%)]\tLoss: 2.680365\n",
      "Train Epoch: 4 [350/382 (92%)]\tLoss: 3.289990\n",
      "Train Epoch: 4 [360/382 (94%)]\tLoss: 3.665968\n",
      "Train Epoch: 4 [370/382 (97%)]\tLoss: 3.282464\n",
      "Train Epoch: 4 [380/382 (99%)]\tLoss: 2.412117\n",
      "Train Epoch: 5 [0/382 (0%)]\tLoss: 3.205164\n",
      "Train Epoch: 5 [10/382 (3%)]\tLoss: 2.473915\n",
      "Train Epoch: 5 [20/382 (5%)]\tLoss: 3.154979\n",
      "Train Epoch: 5 [30/382 (8%)]\tLoss: 2.532476\n",
      "Train Epoch: 5 [40/382 (10%)]\tLoss: 3.463559\n",
      "Train Epoch: 5 [50/382 (13%)]\tLoss: 2.767877\n",
      "Train Epoch: 5 [60/382 (16%)]\tLoss: 3.050507\n",
      "Train Epoch: 5 [70/382 (18%)]\tLoss: 2.481596\n",
      "Train Epoch: 5 [80/382 (21%)]\tLoss: 2.653468\n",
      "Train Epoch: 5 [90/382 (24%)]\tLoss: 2.792887\n",
      "Train Epoch: 5 [100/382 (26%)]\tLoss: 2.724576\n",
      "Train Epoch: 5 [110/382 (29%)]\tLoss: 2.661778\n",
      "Train Epoch: 5 [120/382 (31%)]\tLoss: 2.626724\n",
      "Train Epoch: 5 [130/382 (34%)]\tLoss: 2.622972\n",
      "Train Epoch: 5 [140/382 (37%)]\tLoss: 2.572098\n",
      "Train Epoch: 5 [150/382 (39%)]\tLoss: 2.564718\n",
      "Train Epoch: 5 [160/382 (42%)]\tLoss: 2.619267\n",
      "Train Epoch: 5 [170/382 (45%)]\tLoss: 2.907720\n",
      "Train Epoch: 5 [180/382 (47%)]\tLoss: 2.787632\n",
      "Train Epoch: 5 [190/382 (50%)]\tLoss: 2.150720\n",
      "Train Epoch: 5 [200/382 (52%)]\tLoss: 2.575615\n",
      "Train Epoch: 5 [210/382 (55%)]\tLoss: 2.965200\n",
      "Train Epoch: 5 [220/382 (58%)]\tLoss: 2.029976\n",
      "Train Epoch: 5 [230/382 (60%)]\tLoss: 2.403361\n",
      "Train Epoch: 5 [240/382 (63%)]\tLoss: 1.943493\n",
      "Train Epoch: 5 [250/382 (65%)]\tLoss: 2.825859\n",
      "Train Epoch: 5 [260/382 (68%)]\tLoss: 1.843853\n",
      "Train Epoch: 5 [270/382 (71%)]\tLoss: 2.127822\n",
      "Train Epoch: 5 [280/382 (73%)]\tLoss: 2.379939\n",
      "Train Epoch: 5 [290/382 (76%)]\tLoss: 3.006526\n",
      "Train Epoch: 5 [300/382 (79%)]\tLoss: 2.432223\n",
      "Train Epoch: 5 [310/382 (81%)]\tLoss: 2.604243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m                     epoch, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset),\n\u001b[1;32m     17\u001b[0m                     \u001b[38;5;241m100.\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader), loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[92], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# output.softmax(0)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# output = torch.round(output)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, optimizer, criterion, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.permute(0, 1, 2, 3)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # data = data.view(-1, 256*256)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # output.softmax(0)\n",
    "            # output = torch.round(output)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, i * len(data), len(train_loader.dataset),\n",
    "                    100. * i / len(train_loader), loss.item()))\n",
    "                \n",
    "\n",
    "train(model, train_loader, torch.optim.Adam(model.parameters(), lr=1e-3), nn.CrossEntropyLoss(), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
